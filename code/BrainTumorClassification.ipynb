{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Imports & Drive"],"metadata":{"id":"kCzsNt71zkzn"}},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/ProjectML/data"],"metadata":{"id":"RjVWIF5Jq0Ea","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","from torchvision import models, transforms\n","from tqdm.auto import tqdm\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sns\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"AvQdpHrGq6Df"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Loading & Preprocessing"],"metadata":{"id":"U3uVghnFzpby"}},{"cell_type":"code","source":["TRAIN_PATH = \"training.npz\"\n","TEST_PATH  = \"testing.npz\""],"metadata":{"id":"4Cm-VtWazvaJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_npz = np.load(TRAIN_PATH, allow_pickle=True)\n","test_npz  = np.load(TEST_PATH,  allow_pickle=True)\n","\n","X_full      = train_npz['images']\n","y_full      = train_npz['labels']\n","class_names = train_npz['class_names']\n","\n","X_test = test_npz['images']\n","y_test = test_npz['labels']\n","\n","print(\"Full (to split):\", X_full.shape, y_full.shape)\n","print(\"Test:\", X_test.shape, y_test.shape)\n","print(\"Class names:\", class_names)\n","\n","X_train, X_val, y_train, y_val = train_test_split(\n","    X_full, y_full,\n","    test_size=0.2,\n","    random_state=42,\n","    stratify=y_full\n",")\n","\n","print(\"Train:\", X_train.shape, y_train.shape)\n","print(\"Val:\",   X_val.shape,   y_val.shape)\n","print(\"Test:\",  X_test.shape,  y_test.shape)"],"metadata":{"id":"AwflCUxiq8FM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NumpyDataset(Dataset):\n","    def __init__(self, X, y, transform=None):\n","        self.X = X\n","        self.y = y\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.y)\n","\n","    def __getitem__(self, idx):\n","        img = self.X[idx]\n","        label = self.y[idx]\n","\n","        if img.ndim == 3 and img.shape[-1] in [1,3]:\n","            img = np.transpose(img, (2,0,1))\n","\n","        img = torch.from_numpy(img).float()\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        label = torch.tensor(label).long()\n","        return img, label\n"],"metadata":{"id":"nM2-aWCSxBaV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rYKxFjo3qFe3"},"outputs":[],"source":["data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomRotation(20),\n","        transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n","    ]),\n","    'test': transforms.Compose([\n","        transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n","    ]),\n","}\n","\n","batch_size = 32\n","num_workers = 2\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","train_ds = NumpyDataset(X_train, y_train, transform=data_transforms['train'])\n","val_ds   = NumpyDataset(X_val,   y_val,   transform=data_transforms['val'])\n","test_ds  = NumpyDataset(X_test,  y_test,  transform=data_transforms['test'])\n","\n","train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=num_workers, pin_memory=True)\n","val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n","test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n","\n","dataset_sizes = {'train': len(train_ds), 'val': len(val_ds), 'test': len(test_ds)}\n","print(dataset_sizes)"]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"4axnKWUyz34-"}},{"cell_type":"code","source":["num_classes = len(np.unique(y_train))\n","\n","model = models.mobilenet_v2(pretrained=True)\n","num_ftrs = model.classifier[1].in_features\n","model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n","model = model.to(device)\n","\n","# Freeze\n","for param in model.features.parameters():\n","    param.requires_grad = False\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.classifier.parameters(), lr=1e-3)\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"],"metadata":{"id":"2dHyzrSMrJEF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"xI8ev0aRz6ZF"}},{"cell_type":"markdown","source":["**Early stopping logic**"],"metadata":{"id":"AJwj0Ndv4yWf"}},{"cell_type":"code","source":["class EarlyStopping:\n","    def __init__(self, patience=5, min_delta=0.0, verbose=False):\n","        \"\"\"\n","        Args:\n","            patience (int): how many epochs to wait after last improvement\n","            min_delta (float): minimal change to qualify as an improvement\n","            verbose (bool): whether to print when early‚Äêstop is triggered\n","        \"\"\"\n","        self.patience    = patience\n","        self.min_delta   = min_delta\n","        self.verbose     = verbose\n","        self.best_loss   = float('inf')\n","        self.counter     = 0\n","        self.early_stop  = False\n","\n","    def __call__(self, val_loss, model, best_model_wts):\n","        if val_loss < self.best_loss - self.min_delta:\n","            self.best_loss  = val_loss\n","            self.counter    = 0\n","            best_model_wts  = model.state_dict().copy()\n","        else:\n","            self.counter += 1\n","            if self.verbose:\n","                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        return best_model_wts\n"],"metadata":{"id":"Do2fo35j4x1B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model, criterion, optimizer, scheduler, num_epochs=5, early_stopping=None):\n","    best_model_wts = model.state_dict().copy()\n","    best_acc = 0.0\n","\n","    history = {\n","        'train_loss': [],\n","        'val_loss':   [],\n","        'train_acc':  [],\n","        'val_acc':    []\n","    }\n","\n","    for epoch in range(num_epochs):\n","        print(f\"Epoch {epoch+1}/{num_epochs}\")\n","        print('-'*20)\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","                dataloader = train_loader\n","            else:\n","                model.eval()\n","                dataloader = val_loader\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            with tqdm(dataloader, unit=\"batch\", desc=f\"{phase} Epoch {epoch+1}\") as tepoch:\n","                for inputs, labels in tepoch:\n","                    inputs = inputs.to(device)\n","                    labels = labels.to(device)\n","\n","                    optimizer.zero_grad()\n","                    with torch.set_grad_enabled(phase == 'train'):\n","                        outputs = model(inputs)\n","                        _, preds = torch.max(outputs, 1)\n","                        loss = criterion(outputs, labels)\n","\n","                        if phase == 'train':\n","                            loss.backward()\n","                            optimizer.step()\n","\n","                    running_loss += loss.item() * inputs.size(0)\n","                    running_corrects += torch.sum(preds == labels.data)\n","\n","                    current_loss = running_loss / ((tepoch.n * tepoch.last_print_n) if tepoch.last_print_n else 1)\n","                    tepoch.set_postfix(loss=f\"{loss.item():.4f}\")\n","\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc  = running_corrects.double() / dataset_sizes[phase]\n","\n","            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n","\n","            if phase == 'train':\n","                history['train_loss'].append(epoch_loss)\n","                history['train_acc'].append(epoch_acc.item())\n","            else:\n","                history['val_loss'].append(epoch_loss)\n","                history['val_acc'].append(epoch_acc.item())\n","\n","                if early_stopping is not None:\n","                    best_model_wts = early_stopping(epoch_loss, model, best_model_wts)\n","                    if early_stopping.early_stop:\n","                        print(\"Early stopping triggered.\")\n","                        model.load_state_dict(best_model_wts)\n","                        return model, history\n","\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = model.state_dict().copy()\n","\n","\n","\n","    print(f\"Best val Acc: {best_acc:.4f}\")\n","    model.load_state_dict(best_model_wts)\n","    return model, history\n"],"metadata":{"id":"Dr6Ph2iZrMNw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Hyperparamms**"],"metadata":{"id":"eVLWyZ191bb2"}},{"cell_type":"code","source":["LR = 1e-5\n","STEP_SIZE = 7\n","GAMMA = 0.1\n","EPOCHS = 30\n","BATCH_SIZE = 32\n","PATIENCE = 3"],"metadata":{"id":"IBg6Sw3q1bDu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for param in model.features.parameters():\n","    param.requires_grad = True\n","\n","optimizer_ft = optim.Adam(model.parameters(), lr=LR)\n","exp_lr_scheduler_ft = lr_scheduler.StepLR(optimizer_ft, step_size=STEP_SIZE, gamma=GAMMA)\n","\n","es = EarlyStopping(patience=PATIENCE, min_delta=0.01, verbose=True)\n","\n","model, history = train_model(\n","    model,\n","    criterion,\n","    optimizer_ft,\n","    exp_lr_scheduler_ft,\n","    num_epochs=EPOCHS,\n","    early_stopping=es\n",")"],"metadata":{"id":"0Ep8rEznrRrP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = range(1, len(history['train_loss']) + 1)\n","\n","plt.figure(figsize=(12,5))\n","\n","# Loss subplot\n","plt.subplot(1,2,1)\n","plt.plot(epochs, history['train_loss'], label='Train Loss')\n","plt.plot(epochs, history['val_loss'],   label='Val Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training & Validation Loss')\n","plt.legend()\n","\n","# Accuracy subplot\n","plt.subplot(1,2,2)\n","plt.plot(epochs, history['train_acc'], label='Train Acc')\n","plt.plot(epochs, history['val_acc'],   label='Val Acc')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title('Training & Validation Accuracy')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"XVmX7rqZ3Fn5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing"],"metadata":{"id":"pqzsNJJH3KVb"}},{"cell_type":"code","source":["model.eval()\n","all_preds = []\n","all_labels = []\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","all_preds = np.array(all_preds)\n","all_labels = np.array(all_labels)\n","\n","print(\"Classification Report:\")\n","print(classification_report(all_labels, all_preds, target_names=class_names))\n","\n","cm = confusion_matrix(all_labels, all_preds)\n","plt.figure(figsize=(8,6))\n","sns.heatmap(cm, annot=True, fmt=\"d\",\n","            xticklabels=class_names,\n","            yticklabels=class_names,\n","            cmap=plt.cm.Blues)\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.title('Confusion Matrix')\n","plt.show()"],"metadata":{"id":"xEjJokdvrXO1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Save Checkpoint"],"metadata":{"id":"uiHXwOu63MA-"}},{"cell_type":"code","source":["torch.save(model.state_dict(), 'models/mobilenetv2_finetuned.pth')"],"metadata":{"id":"kSsitDagreeq"},"execution_count":null,"outputs":[]}]}